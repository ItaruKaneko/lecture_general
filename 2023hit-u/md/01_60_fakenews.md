# フェイクニュースについての議論

## フェイクニュースについての寺田先生との議論

昨年度のゼミで、寺田先生から

フェイクニュースについてどう考えるか

というテーマをいただいた。

そこでその時には、講義時間後に、オンラインで以下のような回答を書いた。

「議論 寺田先生とのファクトチェックの議論


寺田先生とのファクトチェックについてのディスカッションは面白かったです。そしてこれはAIのELSIで追及すべき性質と関係があると思います。

僕はすでにファクトチェックについて、個々人が独自のファクトチェックを行う能力を高める、ということが必要だろうと述べました。自称ファクトチェック機関をつくったところで、そのファクトチェックが正しいかどうかはやはり個人個人が判断するしかないからです。

では個人が情報の信頼度を上げようとした場合、SN比をあげていく、ということを行えば良いように思います。

データサイエンスなどで結果の精度を上げたいとしたときに、データを増やすことが重要です。同じデータをいろいろ加工して加えたとしても、それらは独立した情報源ではないから、精度はあがりません。同じデータを何個コピーしてもSN比はあがらない。

たとえば、ある人の顔写真を綺麗に写したいとする。もし10000枚の写真があると、コンピュータでそれらの情報をうまく統合すると非常にきれいな写真にすることができます。しかし1枚の写真をコピーしたものを平均しても、どう加工しても、ノイズは除けない。

では、人から伝わる情報が正しいことをどう担保するか、というと、人類は50億人いるわけですが、それぞれが自分自身が経験できることをしっかりと自分の目と耳で見て他の人に伝え、それを平均して受け取る、ということによって、かなり精度が上がると思います。

人類50憶の情報があってもそれにアクセスできないではないかというと、そうでもなくて、一人が10人の知り合いから情報を得ているとすると、10 hop で100憶になりますから、フィルターバブルなどを避けることができれば、人づてに得た情報も50憶の人類から得た直接情報の平均とすることができます。

こうした状態が保たれるためには、AIと人間の共生において、そうした情報の公平で、バイアスのない情報の流通が促されるようにすればよいように思われる。

それはやはり個々の利用者が、こうした質の高い情報流通を「自分から求めていく」ということが重要ではないかと思います。

AIから見ても実は、より多くの有益な学習データを得ることで性能があがる。相関性の高いデータは情報量が少ないし、ノイズが多いデータも情報の有用性が少ない。

したがって、AIからみても、相関性が低くSN比が高いデータを求めるから、人間の側もそういう情報を発信できる方が高い評価を得られます。

こうして、AIと人間の共生社会において、より信憑性の高い情報の流通が促されるとよいなぁと思います。

が、現状は程遠いので、皆様のご健闘を祈ります。
」

その後いくつか考えることがあったので、以下はそれについてまとめる。

## フェイクニュース対策の定義

まずフェイクニュース対策とはなにか、という点を考える必要がある。

まず、前提として、万人にとっての唯一の真実というものは存在しない。
真実らしさは、すべての個人にとって異なる。

一方、予測の確からしさの「統計」的性質はなりたつ。

そこで、フェイクニュースの問題は以下のように形式化できるように考えられる。

1. 偽情報が少ない状態とはなにか
2. 有害な情報とはなにか
3. その状態に近づけられる制度はなにか


## wisdom of crowd 実験

これは古典的に有名な実験である。

みんなの意見は案外正しい[->リンク](https://ja.wikipedia.org/wiki/%E3%80%8C%E3%81%BF%E3%82%93%E3%81%AA%E3%81%AE%E6%84%8F%E8%A6%8B%E3%80%8D%E3%81%AF%E6%A1%88%E5%A4%96%E6%AD%A3%E3%81%97%E3%81%84)


詳細はwikiから参考文献を探してほしい。

かなりの数のコインが入った瓶を集団に見せる。
この瓶の仲のコインの数を宛てさせる。
その際に以下のようなことが経験的にわかってりる。

1. 全員にコインの数を予想させ、その数を平均すると、もっとも正しい値に近くなる
2. 何人かに「だいたいこのくらい」と予想を述べさせてから全員の予想を書かせると、
最初にのべられた予想に引きずられる結果、平均は正しい値からはなれる

この実験の結果からいえることは、

1. 多数決によりより少ない人数の平均よりも正しい予想ができる可能性がある
2. その際に最初にだれかの意見を述べさせると、多数決のメリットが失われる

フェイクニュースが伝搬する環境でも同じことがいえる。
フェイクニュースの発信者は別にフェイクニュースを流しているという自覚はないかもしれない。
全員が異なる意見を述べればその平均はそれほど真実からずれない。
しかしどの意見をとりあげても、その意見を拡散することによって、全体の意見は
正しい意見からは離れていく。

## ブースティング

機械学習においてブースティングという手法の有効性が知られている。
たとえばランダムフォレスト手法では、一つの高性能な識別器を作るかわりに
単純な識別器を多数用意して、その多数決で結果を出力する。
すると、多くの単純な識別器の多数結がかなりよい結果を出力する。

その際に、もちろん各識別器はなるべく異なる結果を出力するようにする必要がある。
いいかえれば、多様性のある識別機を多数用意することにより多数決の性能があがる。
そのため、たとえば学習データにわざと「ノイズを加えたり」して、
多くの識別器がそれぞれ微妙に異なる判別をするように学習する。

## ベイズ推定における尤度

ベイズ推定においても、独立した情報源は非常に有用であることを確認できる。
一つの情報源から、確実な判別結果が得られることは少ない。
以下のような例はよくあげられる。

95%の制度のドーピング検査がある
そして50人の選手の中にドーピングした選手が一人いる

ある選手のドーピング検査の結果が陽性であった場合、その選手が実際にドーピングしている確率は?

答えは約30%である。95%には届かない。

しかし、精度がもっと低い検査であっても複数の検査を組み合わせて、たとえば3つの検査で陽性であれば、その選手が
ドーピングをしている確率ははるかに高くなる。

## なぜ人間は同調するか

以上二つの例では、

多数決においては、個々の投票がばらつく方が結果の正解率が高い

という例である。人間が多数決を行う際にもできるだけ、
個々の投票者の固有の見解を、それぞれ独立した情報によって検証して、
決定をして投票する。

ということが重要であると言われている。
逆に言えば、別の人に意見に影響された意見や、同一の情報源に
基づく意見の信頼性は低い。

したがって、人間が判断をもとめられた時に、他人の意見に同調するのは合理的ではない
ように思われる。

しかし現実には、woc実験のように、人間は通常他人の意見にかなり同調する。

これは、重要な決定をする集団としては、個々の参加者が独立した判断を
示した方が、精度のよい結果をだせるが、個々の参加者には他人に同調する
ことによって得られる利益があるためではないか、と考えられる。

## データサイエンス的なフェイクニュース対策

すると、データサイエンス的なフェイクニュース対策が考えられる。
この方法では個々の情報の信憑性は判断する必要がない。

一方で、コミュニティに参加する発信者の情報の「相互相関」をとっていく。
他人の意見と相関が高いことは、その判断が正しいことがありえるが、
一方で完全に従属している場合にはその情報の正解率は低い。

このような分析を純粋に数値的に行うことで、情報の信頼度を
数値化することが可能であるかもしれない。

## SNS の劣化に対する放送法の適用

現在のSNSの劣化は、少なくとも「信頼できるはずの情報が実は信頼できない」という
偽サイト問題については、放送法の適用でほぼ解決できると考える。

これについては研究会報告をしようと考えていたが間に合わなかったので下記note記事を示しておく。


ほう、そうか？放送法の活用を考える〜SNSの自由はそのままで、偽広告や偽情報拡散を一掃するシンプルな方法〜

[note へのリンク](https://note.com/it_aru/n/n5769974a9030)

## デジタルゲリマンダーに対する提案

「デジタル・ゲリマンダーとSNS選挙干渉の抑制方法の工学的検討」

[情報処理学会研究報告](http://id.nii.ac.jp/1001/00184538/)

## フェイクニュース対策として考えられる手法

唯一無二の真実を簡単に手にいれそれと相容れないものを排除する、ということは
現実的には不可能だろうと考える。

機械学習や人工知能でもそのような手法はとられていない。ほとんどの対象に
たいしてそのアプローチは失敗する。

したがって、現実的には多くの問題にたいして、絶対的な「正解」はない。

にもかかわらず、現実に偽情報や偽サイトになやまされているのは、非常に高い
確率で偽情報であったり偽サイトであるが、その手がかりも伝達されていない
ことが問題だ。

10万人の研究者のよって日々少しずつ対立する結果が提出され、その
平均値によって裏付けられている効果は、
わずか1000人程度の研究者のおたがいに批判的ではない(相関性の高い)
研究結果の平均よりは、はるかに信頼性が高い。

情報の信頼度は、その情報がどれだけ多くの独立した情報源によって総合的に
裏付けられているか、という単純に量的な比較で決めれば、
現在問題になっているような偽情報、偽サイトは「桁違いに信頼性が低い」
情報として棄却されるのではないかと思われる。

そこで最初に示したフェイクニュースの

1. 偽情報が少ない状態とはなにか
2. 有害な情報とはなにか
3. その状態に近づけられる制度はなにか

の答えを考えると、

### 1. 偽情報が少ない状態とはなにか
もっとも精度の高い多数決が可能な情報交換とその統合が行われている状態

### 2. 有害な情報とはなにか
そのような、正解率の高い状態を乱すような情報の流通
精度を誤認させるような情報や、意見の多様性を減少させる情報

### 3. その状態に近づけられる制度はなにか
独自判断を尊重する仕組み。
情報間の相関や、信頼性を判断するヒントになる情報の流通を補償する仕組み


ここの情報のファクトチェックなどはむしろ有害なこともあり、
情報の多様性を保ち、情報間の相関や、独立した情報源による相互検証を
容易にする仕組みを制度化、整備することが、
有力な対策になるのではないか。

AIにそうした情報提供を機能として備えさせることは、有用であるように思える。
